{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbacce2-409a-419f-bab3-e5a9464a24f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Accuracy: 0.8718\n",
      "Confusion Matrix:\n",
      "[[ 6  4]\n",
      " [ 1 28]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.60      0.71        10\n",
      "           1       0.88      0.97      0.92        29\n",
      "\n",
      "    accuracy                           0.87        39\n",
      "   macro avg       0.87      0.78      0.81        39\n",
      "weighted avg       0.87      0.87      0.86        39\n",
      "\n",
      "ðŸš€ Updated model and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier, DMatrix, train\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'C:\\Users\\aryad\\Downloads\\Parkinson-s-Disease-Detection-main\\Parkinson-s-Disease-Detection-main\\My_New_Flask_app\\cleaned_parkinsons_dataset.csv')\n",
    "\n",
    "# Define features and target\n",
    "# X to train the model, and y to evaluate its accuracy.\n",
    "X = data.drop(columns=['status'])  # Features\n",
    "y = data['status']  # Target (binary: 0 = Healthy, 1 = Parkinson's)\n",
    "\n",
    "# Handle class imbalance dynamically\n",
    "#Dividing by 2 * np.bincount(y) ensures both classes have an equal impact on training.\n",
    "class_weights = len(y) / (2 * np.bincount(y))  # Class weight calculation\n",
    "scale_pos_weight = class_weights[0] / class_weights[1] #more attention to the minority class.\n",
    "\n",
    "# Split dataset\n",
    "#Ensure reproducibility (same split every time).\n",
    "#stratify=y\tMaintains the same class distribution in train/test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()  #Initializes the scaler, which standardizes values using Z-score normalization.\n",
    "X_train = scaler.fit_transform(X_train)#Fits scaler on training data & transforms it (mean=0, std=1).\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Converts NumPy arrays into an optimized format for XGBoost\n",
    "dtrain = DMatrix(X_train, label=y_train)\n",
    "dtest = DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Optimized XGBoost parameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",# binary classification problems\n",
    "    \"eval_metric\": \"logloss\",# how much the model learns at each step.\n",
    "    \"learning_rate\": 0.03,  # Lowered for better generalization\n",
    "    \"max_depth\": 8,  # Increased depth\n",
    "    \"min_child_weight\": 2,  # Adjusted to prevent overfitting,how much data is needed to split a node.\n",
    "    \"gamma\": 0.4,  \n",
    "    \"subsample\": 0.95, #uses 95% of data \n",
    "    \"colsample_bytree\": 0.9,#90% of features used in each tree.\n",
    "    \"scale_pos_weight\": scale_pos_weight,  # Dynamic weight for class balancing\n",
    "    \"reg_alpha\": 0.05,# Reduces unnecessary features.(L1 Regularization)\n",
    "    \"reg_lambda\": 0.05, # (L2 Regularization) â†’ Smoothens weights to prevent extreme values.\n",
    "    \"random_state\": 42, # Ensures same results every time\n",
    "    \"tree_method\": \"hist\"  # Faster computation\n",
    "}\n",
    "\n",
    "# Train model with early stopping\n",
    "xgb_model = train(\n",
    "    params, dtrain,\n",
    "    num_boost_round=500,  # Increased rounds\n",
    "    evals=[(dtest, \"validation\")],\n",
    "    early_stopping_rounds=50,  # Adjusted for better generalization\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = xgb_model.predict(dtest)# to make predictions on the test data (dtest).\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # Proper threshold\n",
    "\n",
    "# Evaluate Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"âœ… Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save model and scaler\n",
    "# joblib.dump(xgb_model, \"xgb_parkinsons_model.pkl\")\n",
    "# joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"ðŸš€ Updated model and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e58fddf-7364-4627-b754-40dc00b36af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa # For audio processing and feature extraction  \n",
    "import numpy as np\n",
    "import joblib # For saving and loading trained models  \n",
    "import gradio as gr\n",
    "import xgboost as xgb  # Ensure XGBoost is imported for DMatrix\n",
    "\n",
    "# Load trained model and scaler\n",
    "model = joblib.load('xgb_parkinsons_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "def extract_features_from_audio(audio_path):\n",
    "    \"\"\"\n",
    "    Extracts relevant audio features ensuring they match the trained model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)  # Load audio with original sampling rate\n",
    "        \n",
    "        # Extract MFCC, Chroma, and Spectral Contrast features\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)#Captures how the voice frequency changes over time.\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1) # Measures the pitch (musical tone) of the voice.\n",
    "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr, fmin=sr * 0.01), axis=1)#Captures the difference between loud and quiet parts of speech.\n",
    "\n",
    "        # Combine features into a single array\n",
    "        features = np.hstack([mfccs, chroma, spectral_contrast])  \n",
    "\n",
    "        # Ensure feature consistency with the trained model\n",
    "        expected_features = scaler.n_features_in_  # Matches trained scaler\n",
    "        if features.shape[0] < expected_features:\n",
    "            features = np.pad(features, (0, expected_features - features.shape[0]), mode='constant')\n",
    "        elif features.shape[0] > expected_features:\n",
    "            features = features[:expected_features]\n",
    "\n",
    "        # Reshape and scale input\n",
    "        features = features.reshape(1, -1)\n",
    "        features = scaler.transform(features)  # Scale using trained scaler\n",
    "\n",
    "        return features  # Return processed features\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)  # Return error message\n",
    "\n",
    "def predict_parkinsons(audio_file):\n",
    "    \"\"\"\n",
    "    Predicts Parkinsonâ€™s disease from a voice recording.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        features = extract_features_from_audio(audio_file)\n",
    "        \n",
    "        if isinstance(features, str):  # If an error occurred\n",
    "            return f\"please enter .wav file: {features}\"\n",
    "\n",
    "        # Convert to DMatrix for XGBoost prediction\n",
    "        dmatrix_features = xgb.DMatrix(features)\n",
    "\n",
    "        # Get prediction probability\n",
    "        probability = model.predict(dmatrix_features)[0]  \n",
    "\n",
    "        # Convert probability to a classification result\n",
    "        result = \"Parkinson's Detected ðŸŸ \" if probability > 0.5 else \"Healthy âœ…\"\n",
    "        return f\"Prediction: {result} (Confidence: {probability:.2f})\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Prediction Error: {str(e)}\"\n",
    "\n",
    "#Gradio UI\n",
    "iface = gr.Interface(\n",
    "    fn=predict_parkinsons,\n",
    "    inputs=gr.Audio(type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Parkinson's Detection from Voice\",\n",
    "    description=\"Upload a .wav file to check if Parkinsonâ€™s is detected.\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d5a7a-603f-40a8-bb9c-e99a63e05647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9b378-769a-449e-ae71-ac04888310c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fca48c-8794-4d90-bef4-b432f3a592cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85132b56-e962-4cd5-965a-d06e3b738853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
